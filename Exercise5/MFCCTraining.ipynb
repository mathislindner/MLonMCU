{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC feature extraction and Network training\n",
    "\n",
    "In this notebook you will go through an example flow of processing audio data, complete with feature extraction and training.\n",
    "\n",
    "Make sure you read the instructions on the exercise sheet and follow the task order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  50659\n",
      "Number of test samples:  23072\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "DataSetPath = \"data/hey_snips_research_6k_en_train_eval_clean_ter/\"\n",
    "\n",
    "with open(DataSetPath+\"train.json\") as jsonfile:\n",
    "    traindata = json.load(jsonfile)\n",
    "\n",
    "with open(DataSetPath+\"test.json\") as jsonfile:\n",
    "    testdata = json.load(jsonfile)\n",
    "\n",
    "print(\"Number of training samples: \", len(traindata))\n",
    "print(\"Number of test samples: \", len(testdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function: load_data\n",
    "--------------------\n",
    "Loads the dataset and returns the training and testing data as numpy arrays\n",
    "Initializes the training and testing data as lists, then iterates over the\n",
    "training and testing data and appends the data to the lists. The data is\n",
    "segmented into 1024 sample segments with 0 overlap. The data is then zero\n",
    "stuffed to a length of 10 seconds. The data is then converted to a tensor and\n",
    "returned. TQDM is used to display a progress bar.\n",
    "\"\"\"\n",
    "def load_data():\n",
    "    x_train_list = []\n",
    "    y_train_list = []\n",
    "\n",
    "    x_test_list = []\n",
    "    y_test_list = []\n",
    "\n",
    "    totalSliceLength = 10 # Length to stuff the signals to, given in seconds\n",
    "\n",
    "    # Load the full dataset, this will take a while\n",
    "    # trainsize = len(traindata) # Number of loaded training samples\n",
    "    # testsize = len(testdata) # Number of loaded testing samples\n",
    "\n",
    "    # Load a subset of the dataset, this will be much faster\n",
    "    trainsize = 1000 # Number of loaded training samples\n",
    "    testsize = 100 # Number of loaded testing samples\n",
    "\n",
    "    fs = 16000 # Sampling rate of the samples\n",
    "    segmentLength = 1024 # Number of samples to use per segment\n",
    "\n",
    "    # the slice length corresponds to the total length of the signal in seconds\n",
    "    sliceLength = int(totalSliceLength * fs / segmentLength)*segmentLength\n",
    "\n",
    "    for i in tqdm(range(trainsize)): \n",
    "        fs, train_sound_data = wavfile.read(DataSetPath+traindata[i]['audio_file_path']) # Read wavfile to extract amplitudes\n",
    "\n",
    "        _x_train = train_sound_data.copy() # Get a mutable copy of the wavfile\n",
    "        _x_train.resize(sliceLength) # Zero stuff the single to a length of sliceLength\n",
    "        _x_train = _x_train.reshape(-1,int(segmentLength)) # Split slice into Segments with 0 overlap\n",
    "        x_train_list.append(_x_train.astype(np.float32)) # Add segmented slice to training sample list, cast to float so librosa doesn't complain\n",
    "        y_train_list.append(traindata[i]['is_hotword']) # Read label \n",
    "\n",
    "    for i in tqdm(range(testsize)):\n",
    "        fs, test_sound_data = wavfile.read(DataSetPath+testdata[i]['audio_file_path'])\n",
    "        _x_test = test_sound_data.copy()\n",
    "        _x_test.resize(sliceLength)\n",
    "        _x_test = _x_test.reshape((-1,int(segmentLength)))\n",
    "        x_test_list.append(_x_test.astype(np.float32))\n",
    "        y_test_list.append(testdata[i]['is_hotword'])\n",
    "\n",
    "    x_train = tf.convert_to_tensor(np.asarray(x_train_list))\n",
    "    y_train = tf.convert_to_tensor(np.asarray(y_train_list))\n",
    "\n",
    "    x_test = tf.convert_to_tensor(np.asarray(x_test_list))\n",
    "    y_test = tf.convert_to_tensor(np.asarray(y_test_list))\n",
    "\n",
    "    # Printing the shapes is useful to see if the data is loaded correctly\n",
    "    # and gives you an idea how to set the parameters for the model properly\n",
    "    print(\"Training data shape: \", x_train.shape)\n",
    "    print(\"Training labels shape: \", y_train.shape)\n",
    "    print(\"Testing data shape: \", x_test.shape)\n",
    "    print(\"Testing labels shape: \", y_test.shape)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function: compute_mfccs\n",
    "-----------------------\n",
    "Computes the MFCCs of the input tensor. The MFCCs are computed using the\n",
    "following parameters:\n",
    "    sample_rate = 16000.0 \n",
    "    lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 7600.0, 80 (Mel filterbank)\n",
    "    frame_length = 1024 (1024 samples per frame)\n",
    "    num_mfcc = 13 (13 MFCCs)\n",
    "\"\"\"\n",
    "def compute_mfccs(tensor):\n",
    "    sample_rate = 16000.0\n",
    "    lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 7600.0, 80\n",
    "    frame_length = 1024\n",
    "    num_mfcc = 13\n",
    "\n",
    "    stfts = tf.signal.stft(tensor, frame_length=frame_length, frame_step=frame_length, fft_length=frame_length)\n",
    "    spectrograms = tf.abs(stfts)\n",
    "    spectrograms = tf.reshape(spectrograms, (spectrograms.shape[0],spectrograms.shape[1],-1))\n",
    "    num_spectrogram_bins = stfts.shape[-1]\n",
    "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "      num_mel_bins, num_spectrogram_bins, sample_rate, lower_edge_hertz,\n",
    "      upper_edge_hertz)\n",
    "    mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)\n",
    "    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "    mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrograms)[..., :num_mfcc]\n",
    "    return tf.reshape(mfccs, (mfccs.shape[0],mfccs.shape[1],mfccs.shape[2],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:08<00:00, 115.05it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 119.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (1000, 156, 1024)\n",
      "Training labels shape:  (1000,)\n",
      "Testing data shape:  (100, 156, 1024)\n",
      "Testing labels shape:  (100,)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "x_train, y_train, x_test, y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 156, 13, 1)\n",
      "(100, 156, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_mfcc = compute_mfccs(x_train)\n",
    "x_test_mfcc = compute_mfccs(x_test)\n",
    "\n",
    "print(x_train_mfcc.shape)\n",
    "print(x_test_mfcc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training data size without compression:  159744000\n",
      "Total training data size with compression:  2028000\n",
      "Compression ratio:  78.76923076923077\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute the compression ratio between the original data and the MFCCs\n",
    "total_train_size_no_compression = x_train.numpy().flatten().shape[0]\n",
    "total_train_size_with_compression = x_train_mfcc.numpy().flatten().shape[0]\n",
    "\n",
    "print(\"Total training data size without compression: \", total_train_size_no_compression)\n",
    "print(\"Total training data size with compression: \", total_train_size_with_compression)\n",
    "print(\"Compression ratio: \", total_train_size_no_compression/total_train_size_with_compression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 10\n",
    "epochs = 30\n",
    "\n",
    "# we normalize the data to be in the range [0,1]\n",
    "# this is done by dividing by 512 and adding 0.5\n",
    "# this is because the MFCCs are in the range [-512, 512]\n",
    "# and adding 0.5 shifts the range to [0,1]\n",
    "\n",
    "\n",
    "train_set = (x_train_mfcc/512 + 0.5)\n",
    "train_labels = y_train\n",
    "\n",
    "test_set = (x_test_mfcc/512 + 0.5)\n",
    "test_labels = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 6s 20ms/step - loss: 0.2803 - accuracy: 0.9020\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.1557 - accuracy: 0.9310\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1230 - accuracy: 0.9310\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0945 - accuracy: 0.9530\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.0681 - accuracy: 0.9750\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0528 - accuracy: 0.9840\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.0446 - accuracy: 0.9840\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0373 - accuracy: 0.9900\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0286 - accuracy: 0.9900\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0372 - accuracy: 0.9880\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0185 - accuracy: 0.9970\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.0295 - accuracy: 0.9900\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.0198 - accuracy: 0.9920\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.0114 - accuracy: 0.9970\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0090 - accuracy: 0.9990\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0139 - accuracy: 0.9930\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0209 - accuracy: 0.9940\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0166 - accuracy: 0.9960\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.0064 - accuracy: 0.9980\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 6.9314e-04 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 9.3486e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 7.7507e-04 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.0260 - accuracy: 0.9940\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.0332 - accuracy: 0.9880\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.0100 - accuracy: 0.9970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a7741b46d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#model.add(layers.InputLayer(input_shape=(train_set.shape[1],train_set.shape[2],train_set.shape[3]), batch_size=(batchSize)))\n",
    "model.add(layers.Conv2D(filters=3,kernel_size=(3,3),padding=\"same\",input_shape=(train_set[0].shape)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Conv2D(filters=16,kernel_size=(3,3),strides=(2,2),padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=32,kernel_size=(3,3),strides=(2,2),padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(filters=48,kernel_size=(3,3),padding='same',strides=(2,2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(8, kernel_regularizer=(regularizers.l1(0))))\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Dense(2))\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model.fit(train_set, y_train, batchSize, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 156, 13, 3)        30        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 156, 13, 3)       12        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 156, 13, 3)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 78, 7, 16)         448       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 78, 7, 16)        64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 78, 7, 16)         0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 39, 3, 16)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 20, 2, 32)         4640      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 20, 2, 32)        128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 20, 2, 32)         0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 10, 1, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 5, 1, 48)          13872     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 5, 1, 48)         192       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 5, 1, 48)          0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 48)               0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 48)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 392       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 18        \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,796\n",
      "Trainable params: 19,598\n",
      "Non-trainable params: 198\n",
      "_________________________________________________________________\n",
      "4/4 [==============================] - 1s 12ms/step - loss: 0.8381 - accuracy: 0.8100\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "score = model.evaluate(test_set, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk at location:  c:\\Users\\mathi\\Documents\\GitHub\\MLonMCU_exercise_5\\Exercise5\n"
     ]
    }
   ],
   "source": [
    "model.save(\"MFCCmodel.h5\")\n",
    "print(\"Saved model to disk at location: \", os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 8: TFLite conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\mathi\\AppData\\Local\\Temp\\tmpygfb0l7l\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\mathi\\AppData\\Local\\Temp\\tmpygfb0l7l\\assets\n",
      "c:\\Users\\mathi\\Anaconda3\\envs\\mlonmcu\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28272"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = train_set.numpy()\n",
    "test_set = test_set.numpy()\n",
    "train_labels = train_labels.numpy()\n",
    "test_labels = test_labels.numpy()\n",
    "tflite_model_name = 'MFCC'\n",
    "# Convert Keras model to a tflite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "quantize = True\n",
    "if (quantize):\n",
    "    def representative_dataset():\n",
    "        for i in range(500):\n",
    "            yield([train_set[i].reshape(1,156,13,1)])\n",
    "    # Set the optimization flag.\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # Enforce full-int8 quantization\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "    converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "    # Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(tflite_model_name + '.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert some hex value into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "\n",
    "    c_str = ''\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    # Add array length at top of file\n",
    "    c_str += '\\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'unsigned char ' + var_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data) :\n",
    "\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add formatting so each line stays within 80 characters\n",
    "        if (i + 1) < len(hex_data):\n",
    "            hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "            hex_str += '\\n '\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "    return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model_name = 'MFCC'\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open(c_model_name + '.h', 'w') as file:\n",
    "    file.write(hex_to_c_array(tflite_model, c_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input details ==\n",
      "name: serving_default_conv2d_input:0\n",
      "shape: [  1 156  13   1]\n",
      "type: <class 'numpy.int8'>\n",
      "\n",
      "== Output details ==\n",
      "name: StatefulPartitionedCall:0\n",
      "shape: [1 2]\n",
      "type: <class 'numpy.int8'>\n"
     ]
    }
   ],
   "source": [
    "tflite_interpreter = tf.lite.Interpreter(model_path=tflite_model_name + '.tflite')\n",
    "tflite_interpreter.allocate_tensors()\n",
    "input_details = tflite_interpreter.get_input_details()\n",
    "output_details = tflite_interpreter.get_output_details()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", input_details[0]['name'])\n",
    "print(\"shape:\", input_details[0]['shape'])\n",
    "print(\"type:\", input_details[0]['dtype'])\n",
    "\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\", output_details[0]['name'])\n",
    "print(\"shape:\", output_details[0]['shape'])\n",
    "print(\"type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros((len(test_set),), dtype=int)\n",
    "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "for i in range(len(test_set)):\n",
    "    val_batch = test_set[i]\n",
    "    val_batch = val_batch / input_scale + input_zero_point\n",
    "    val_batch = np.expand_dims(val_batch, axis=0).astype(input_details[0][\"dtype\"])\n",
    "    tflite_interpreter.set_tensor(input_details[0]['index'], val_batch)\n",
    "    tflite_interpreter.allocate_tensors()\n",
    "    tflite_interpreter.invoke()\n",
    "\n",
    "    tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "    #print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "    output = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "    predictions[i] = output.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of quantized to int8 model is 81.0%\n",
      "Compared to float32 accuracy of 81.00000023841858%\n",
      "We have a change of -2.3841857377249198e-07%\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in range(len(predictions)):\n",
    "    if (predictions[i] == test_labels[i]):\n",
    "        sum = sum + 1\n",
    "accuracy_score = sum / 100\n",
    "print(\"Accuracy of quantized to int8 model is {}%\".format(accuracy_score*100))\n",
    "print(\"Compared to float32 accuracy of {}%\".format(score[1]*100))\n",
    "print(\"We have a change of {}%\".format((accuracy_score-score[1])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
