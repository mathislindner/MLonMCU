{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning on MCU - Ex4\n",
    "\n",
    "# Feature Extraction & Regularization in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def generate_data(lowest, highest, amount):\n",
    "    x = np.linspace(lowest, highest, num=amount)\n",
    "    y = []\n",
    "    noise = 400\n",
    "    random.seed(123)\n",
    "\n",
    "    for p in x:\n",
    "        y.append(10 + 0.5*p - 0.08*p**2 - 0.002*p**3 + 0.0003*p**4 - 0.00001*p**5 + random.randint(-noise,noise)/100)\n",
    "  \n",
    "    return x, y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate some data based on parameters\n",
    "lowest = 10\n",
    "highest = 20\n",
    "amount = 100\n",
    "\n",
    "x, y = generate_data(lowest, highest, amount)\n",
    "\n",
    "# Do the regression while plotting\n",
    "models = []\n",
    "degrees = [1, 4, 5, 6, 10]\n",
    "\n",
    "line = np.linspace(lowest, highest, 100)\n",
    "\n",
    "\n",
    "for i, deg in enumerate(degrees):\n",
    "    plt.scatter(x, y)\n",
    "    plt.title(\"Polynomial Regression\")\n",
    "    p, residuals, rank, singular_values, rcond = np.polyfit(x, y, deg, full=True)\n",
    "    print(residuals)\n",
    "    models.append(np.poly1d(p))\n",
    "    plt.plot(line, models[i](line), label = \"n=\"+str(deg))\n",
    "    plt.legend()\n",
    "    plt.show() \n",
    "\n",
    "# Generate data based on new parameters\n",
    "lowest = 8 \n",
    "highest = 22\n",
    "amount = 25\n",
    "\n",
    "line = np.linspace(lowest, highest, 100)\n",
    "x, y = generate_data(lowest, highest, amount)\n",
    "\n",
    "# Plot without fitting to see how the models generalize\n",
    "for i, deg in enumerate(degrees):\n",
    "    plt.title(\"Polynomial Regression\")\n",
    "    plt.scatter(x, y, c=\"C{}\".format(0))\n",
    "    plt.plot(line, models[i](line), label = \"n=\"+str(deg))\n",
    "    plt.legend()\n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "def shuffle_lists(x, y):\n",
    "    data = list(zip(x, y))\n",
    "    random.shuffle(data)\n",
    "    x, y = zip(*data)\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    return x, y\n",
    "\n",
    "def normalize_data(x):\n",
    "    mean = np.mean(x)\n",
    "    x = x-mean\n",
    "    dev = np.max(x)\n",
    "    x = x/dev\n",
    "    return x, mean, dev\n",
    "\n",
    "def generate_data(lowest, highest, amount):\n",
    "    x = np.linspace(lowest, highest, num=amount)\n",
    "    y = []\n",
    "    noise = 1000\n",
    "    random.seed(123)\n",
    "\n",
    "    for p in x:\n",
    "        y.append(10 + 0.5*p - 0.04*p**2 + 0.002*p**3 + 0.0003*p**4 - 0.00001*p**5 + random.randint(-noise,noise)/100)\n",
    "  \n",
    "    return x, y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "dropout   = False\n",
    "batchnorm = False\n",
    "normalize = True\n",
    "\n",
    "batch_size = 16\n",
    "no_epochs = 100\n",
    "optimizer = Adam()\n",
    "validation_split = 0.1\n",
    "plot_name = \"plot_default.pdf\"\n",
    "\n",
    "# Regularization techniques\n",
    "if dropout:\n",
    "    from tensorflow.keras.layers import Dropout\n",
    "    dropout_rate = 0.2\n",
    "    dropout = True\n",
    "    plot_name = \"plot_dropout.pdf\"\n",
    "if batchnorm:\n",
    "    from tensorflow.keras.layers import BatchNormalization\n",
    "    batchnorm = True\n",
    "    plot_name = \"plot_batchnorm.pdf\"\n",
    "\n",
    "# Generate data\n",
    "dataset_size = 100\n",
    "\n",
    "x, y = generate_data(10, 20, dataset_size)\n",
    "input_train, target_train =  shuffle_lists(x, y)\n",
    "\n",
    "validation_size = 10\n",
    "x, y = generate_data(8, 22, validation_size)\n",
    "input_test, target_test =  shuffle_lists(x, y)\n",
    "\n",
    "if normalize:\n",
    "    input_train, mean_in, dev_in = normalize_data(input_train)\n",
    "    target_train, mean_tar, dev_tar = normalize_data(target_train)\n",
    "    input_test = (input_test-mean_in)/dev_in\n",
    "    target_test = (target_test-mean_tar)/dev_tar\n",
    "\n",
    "input_train  = input_train.reshape(len(input_train), 1)\n",
    "target_train = target_train.reshape(len(target_train), 1)\n",
    "input_test   = input_test.reshape(len(input_test), 1)\n",
    "target_test  = target_test.reshape(len(target_test), 1)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation=lambda x: x**2, input_dim=1))\n",
    "model.add(Dense(512, activation='elu'))\n",
    "if dropout:\n",
    "    model.add(Dropout(dropout_rate))\n",
    "if batchnorm:\n",
    "    model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='elu'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=MeanSquaredError(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit model to data\n",
    "set_seed(123)\n",
    "history = model.fit(input_train,\n",
    "                    target_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=no_epochs,\n",
    "                    verbose=True,\n",
    "                    validation_split=validation_split)\n",
    "\n",
    "# Generate generalization metrics\n",
    "score = model.evaluate(input_test, target_test, verbose=0)\n",
    "print(f'Test loss: {score[0]}')\n",
    "\n",
    "# Visualize history\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "\n",
    "# Plot loss history\n",
    "ax[0].plot(history.history['loss'], label='Training')\n",
    "ax[0].plot(history.history['val_loss'], label='Validation')\n",
    "ax[0].set_title('Loss History')\n",
    "ax[0].set_ylabel('Value')\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].legend()\n",
    "\n",
    "# Plot predictions\n",
    "if normalize:\n",
    "  linspace = np.linspace(-1.4, 1.4, 100)\n",
    "else:\n",
    "  linspace = np.linspace(8, 22, 100)\n",
    "\n",
    "pred = model.predict(linspace)\n",
    "ax[1].scatter(input_test, target_test, label='Data')\n",
    "ax[1].plot(linspace, pred, label='Model')\n",
    "ax[1].set_title('Predictions')\n",
    "ax[1].legend()\n",
    "\n",
    "# Save plot\n",
    "plt.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Audio Feature Extraction\n",
    "\n",
    "In this Notebook, we provide an example on how to:\n",
    "\n",
    "- Load an audio file stored in your PC\n",
    "- Visualize it\n",
    "- Extract its MFCCs\n",
    "\n",
    "This is an example of feature extraction.\n",
    "\n",
    "To complete this exercise, you need for a *wav* file. You can download one from here: https://freewavesamples.com/files/Ensoniq-ZR-76-01-Dope-77.wav\n",
    "\n",
    "First of all, we import the useful modules we need. If something goes wrong, you need to download and install the required packages first (use Anaconda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we load the audio into our program. Set the correct path to your *wav* file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '/PATH/TO/AUDIO.wav'\n",
    "\n",
    "y, sr = librosa.load(audio_path, sr=44100, duration=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of samples... but how many? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of samples: ' + str(np.size(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also play the audio and bother the other people with annoying loud sounds! Super fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use *librosa* to visualize the audio track. We need the samples and the sampling rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(y, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform *feature extraction* to reduce the amount of data to process next. \n",
    "\n",
    "To do so, let's extract the MFCCs for this audio; using the default parameters of librosa's function, we will end up with 20 MFCCs per audio's frame. \n",
    "*librosa* will take care of the division in frames, analysis and MFCCs extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 20 coefficients per frame. Let's see how many frames we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "print('(#MFCCs, #frames): ' + str(mfccs.shape))\n",
    "print('Total number of MFCCs: ' + str(np.size(mfccs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We have {} frames with {} MFCCs each. Not bad!'.format(mfccs.shape[1], mfccs.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But let's plot them... We guess they are super-cool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our fresh MFCCs are ready to be processed!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
